# mdocourse
This webpage contains **only** tutorials.
The slides of the different courses are available on *SUPAERO's LMS*. 

1st MATLAB tutorial on [Complex-step derivatives](http://htmlpreview.github.io/?https://github.com/jomorlier/mdocourse2018/blob/master/ComplexStep/ComplexStep.html)

Estimate derivatives by simply passing in a complex number to your function.
A single (complex) function evaluations computes both the function's value **(Re)** and the derivative **(Im)**.
Is it **always** possible to do this? I mean with a standard code form industry (Nastran, Fluent etc...)?

2nd MATLAB tutorial on [gradient evaluation](http://htmlpreview.github.io/?https://github.com/jomorlier/mdocourse2018/blob/master/Sensibility/sensitivity_TD.html)

Comparison of **Symbolic/Finite Differences/DIRECT/ADJOINT Method** on a really simple mechanical system (2DOFs).
Play with the code for **checking** Symbolic with Finite Differences. Play with $\delta_x$ ?
By the way, just add the complex step approach, not so difficult when you have access to the **original** code.
Oh, at the end which method is exact? 

3nd MATLAB tutorial on regression using [GP, or Kriging](http://htmlpreview.github.io/?https://github.com/jomorlier/mdocourse2018/blob/master/GP_Tutorial/GP_Tutorial.html)

It's always working ? On interpolation **and** extrapolation ?
By the way, GP is an interpolating **or** regressing method ? Play with the code.
